{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///Users/mogithpn/work/litellm-fork\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from litellm==1.35.12) (3.8.6)\n",
      "Requirement already satisfied: click in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from litellm==1.35.12) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from litellm==1.35.12) (6.8.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from litellm==1.35.12) (3.1.3)\n",
      "Requirement already satisfied: openai>=1.0.0 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from litellm==1.35.12) (1.16.1)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from litellm==1.35.12) (1.0.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from litellm==1.35.12) (2.31.0)\n",
      "Requirement already satisfied: tiktoken>=0.4.0 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from litellm==1.35.12) (0.5.1)\n",
      "Requirement already satisfied: tokenizers in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from litellm==1.35.12) (0.19.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from importlib-metadata>=6.8.0->litellm==1.35.12) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from jinja2<4.0.0,>=3.1.2->litellm==1.35.12) (2.1.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from openai>=1.0.0->litellm==1.35.12) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from openai>=1.0.0->litellm==1.35.12) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from openai>=1.0.0->litellm==1.35.12) (0.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from openai>=1.0.0->litellm==1.35.12) (2.4.2)\n",
      "Requirement already satisfied: sniffio in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from openai>=1.0.0->litellm==1.35.12) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from openai>=1.0.0->litellm==1.35.12) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from openai>=1.0.0->litellm==1.35.12) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from requests<3.0.0,>=2.31.0->litellm==1.35.12) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from requests<3.0.0,>=2.31.0->litellm==1.35.12) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from requests<3.0.0,>=2.31.0->litellm==1.35.12) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from requests<3.0.0,>=2.31.0->litellm==1.35.12) (2023.7.22)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from tiktoken>=0.4.0->litellm==1.35.12) (2023.10.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from aiohttp->litellm==1.35.12) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from aiohttp->litellm==1.35.12) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from aiohttp->litellm==1.35.12) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from aiohttp->litellm==1.35.12) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from aiohttp->litellm==1.35.12) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from aiohttp->litellm==1.35.12) (1.3.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from tokenizers->litellm==1.35.12) (0.20.2)\n",
      "Requirement already satisfied: exceptiongroup in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai>=1.0.0->litellm==1.35.12) (1.1.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai>=1.0.0->litellm==1.35.12) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0.0->litellm==1.35.12) (0.14.0)\n",
      "Requirement already satisfied: filelock in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.35.12) (3.12.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.35.12) (2023.10.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.35.12) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm==1.35.12) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai>=1.0.0->litellm==1.35.12) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /Users/mogithpn/.pyenv/versions/3.9.10/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai>=1.0.0->litellm==1.35.12) (2.10.1)\n",
      "Building wheels for collected packages: litellm\n",
      "  Building editable for litellm (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for litellm: filename=litellm-1.35.12-py3-none-any.whl size=7294 sha256=582e3be443f72b760788c85a50c2105c9e5ccb1accd271bc27000186d6b81c34\n",
      "  Stored in directory: /private/var/folders/t9/ws_lrgcx2hq7qxs7r0kmk8q00000gn/T/pip-ephem-wheel-cache-ituzqpvk/wheels/5b/57/f9/b3eab094a33be21ce994be2eb8150b6fffebdc6c9835cd2d84\n",
      "Successfully built litellm\n",
      "Installing collected packages: litellm\n",
      "  Attempting uninstall: litellm\n",
      "    Found existing installation: litellm 1.35.12\n",
      "    Uninstalling litellm-1.35.12:\n",
      "      Successfully uninstalled litellm-1.35.12\n",
      "Successfully installed litellm-1.35.12\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import litellm\n",
    "from litellm import completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CLARIFAI_API_KEY\"] = \"c75cc032415e45368be331fdd2c06db0\" #@param\n",
    "user_message = \"\"\"Hello, whats the weather in San Francisco??\"\"\"\n",
    "messages = [{ \"content\": user_message,\"role\": \"user\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "litellm.set_verbose=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claude-2_1\n",
      " custom_llm_provider: clarifai, and name of model in factory.py: claude-2.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelResponse(id='chatcmpl-e165525a-550e-4702-b6ec-15424d9b8ce1', choices=[Choices(finish_reason='stop', index=1, message=Message(content=\" Unfortunately, I do not have up-to-date access to weather conditions in specific locations. As an AI assistant without direct access to meteorological data, I don't have the latest details on the weather in San Francisco. I'd be happy to provide general weather information if I had it, but cannot give you a precise real-time weather report for a given city. Please check with a dedicated weather website or app for the most accurate and up-to-date forecast in San Francisco.\", role='assistant'))], created=1713805766, model='https://api.clarifai.com/v2/users/anthropic/apps/completion/models/claude-2_1/outputs', object='chat.completion', system_fingerprint=None, usage=Usage(prompt_tokens=15, completion_tokens=94, total_tokens=109))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"clarifai/anthropic.completion.claude-2_1\"\n",
    "response = completion(model=model_name, messages=messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"clarifai/anthropic.completion.claude-v2\"\n",
    "response = completion(model=model_name, messages=messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"clarifai/anthropic.completion.claude-v1\"\n",
    "response = completion(model=model_name, messages=messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"clarifai/anthropic.completion.claude-instant-1_2\"\n",
    "response = completion(model=model_name, messages=messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"clarifai/anthropic.completion.claude-3-opus\"\n",
    "response = completion(model=model_name, messages=messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"clarifai/meta.Llama-3.Llama-3-8B-Instruct\"\n",
    "response = completion(model=model_name, messages=messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"clarifai/mistralai.completion.mistral-large\"\n",
    "response = completion(model=model_name, messages=messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"clarifai/mistralai.completion.mistral-small\"\n",
    "response = completion(model=model_name, messages=messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"clarifai/mistralai.completion.mistral-medium\"\n",
    "response = completion(model=model_name, messages=messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"clarifai/mistralai.completion.mixtral-8x22B\"\n",
    "response = completion(model=model_name, messages=messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemini-pro\n",
      " custom_llm_provider: , and name of model in factory.py: gemini-pro\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelResponse(id='chatcmpl-0cc22a83-68ec-4b0c-acc2-24c4eee2aebc', choices=[Choices(finish_reason='stop', index=1, message=Message(content='The weather in San Francisco is currently mild and pleasant, with a temperature of 62 degrees Fahrenheit and partly cloudy skies. It is a perfect day for a walk in the park or a visit to the beach. I hope you enjoy your time in San Francisco!\\n\\nHere is a more detailed forecast for the next few days:\\n\\n* **Today:** Partly cloudy, with a high of 62 degrees Fahrenheit and a low of 50 degrees Fahrenheit.\\n* **Tomorrow:** Mostly sunny, with a high of 65 degrees Fahrenheit and a low of 52 degrees Fahrenheit.\\n* **Thursday:** Sunny, with a high of 68 degrees Fahrenheit and a low of 54 degrees Fahrenheit.\\n* **Friday:** Partly cloudy, with a high of 66 degrees Fahrenheit and a low of 53 degrees Fahrenheit.\\n* **Saturday:** Mostly sunny, with a high of 64 degrees Fahrenheit and a low of 51 degrees Fahrenheit.\\n* **Sunday:** Sunny, with a high of 67 degrees Fahrenheit and a low of 53 degrees Fahrenheit.\\n\\nPlease note that this is just a general forecast and the actual weather may vary. It is always a good idea to check the latest forecast before heading out.', role='assistant'))], created=1713805779, model='https://api.clarifai.com/v2/users/gcp/apps/generate/models/gemini-pro/outputs', object='chat.completion', system_fingerprint=None, usage=Usage(prompt_tokens=9, completion_tokens=239, total_tokens=248))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"clarifai/gcp.generate.gemini-pro\"\n",
    "response = completion(model=model_name, messages=messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dbrx-instruct\n",
      " custom_llm_provider: , and name of model in factory.py: dbrx-instruct\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelResponse(id='chatcmpl-7f2d16e6-2516-46a7-9d90-dcbf2a1c12f1', choices=[Choices(finish_reason='stop', index=1, message=Message(content=\"I'd be happy to help you with that! Let me check the current weather in San Francisco for you.\\n\\nAs of my last update, the weather in San Francisco is currently partly cloudy with a temperature of around 64°F (18°C). However, please note that weather conditions can change rapidly, so it's always a good idea to check a reliable weather forecasting website or app for the most up-to-date information.\\n\\nIs there anything else I can help you with? I'm here to assist you with any questions or tasks you have!\", role='assistant'))], created=1713805805, model='https://api.clarifai.com/v2/users/databricks/apps/drbx/models/dbrx-instruct/outputs', object='chat.completion', system_fingerprint=None, usage=Usage(prompt_tokens=9, completion_tokens=108, total_tokens=117))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"clarifai/databricks.drbx.dbrx-instruct\"\n",
    "response = completion(model=model_name, messages=messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'accept': 'application/json', 'content-type': 'application/json', 'Authorization': 'Bearer c75cc032415e45368be331fdd2c06db0'}\n",
    "data = {'inputs': [{'data': {'text': {'raw': 'Human: Hello, whats the weather in San Francisco??\\n Assistant:'}}}], 'model': {'output_info': {'params': {}}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "response = requests.post(\n",
    "        \"https://api.clarifai.com/v2/users/anthropic/apps/completion/models/claude-2_1/outputs\",\n",
    "        headers=headers,\n",
    "        data=json.dumps(data),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"clarifai/openai.chat-completion.GPT-4\"\n",
    "response = completion(model=model_name, messages=messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"clarifai/mistralai.completion.mistral-7B-Instruct\"\n",
    "response = completion(model=model_name, messages=messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model=\"anthropic.completion.claude-2_1\"\n",
    "user_id, app_id, model_id = modelsplit(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params={\"openAI:GPT-4-turbo\":\"https://clarifai.com/openai/chat-completion/models/gpt-4-turbo\",\n",
    "                  \"openAI:GPT-4\":\"https://clarifai.com/openai/chat-completion/models/GPT-4\",\n",
    "                  \"Anthropic:claude-3-opus\":\"https://clarifai.com/anthropic/completion/models/claude-3-opus\",\n",
    "                  \"Anthropic:claude-v2\":\"https://clarifai.com/anthropic/completion/models/claude-v2\",\n",
    "                  \"Anthropic:claude-2.1\":\"https://clarifai.com/anthropic/completion/models/claude-2_1\",\n",
    "                  \"Anthropic:claude-v1\":\"https://clarifai.com/anthropic/completion/models/claude-v1\",\n",
    "                  \"Anthropic:claude-instant-1.2\":\"https://clarifai.com/anthropic/completion/models/claude-instant-1_2\",\n",
    "                  \"llama3-8B-Instruct\":\"https://clarifai.com/meta/Llama-3/models/Llama-3-8B-Instruct\",\n",
    "                  \"llama2-70B-chat\":\"https://clarifai.com/meta/Llama-2/models/llama2-70b-chat\",\n",
    "                  \"mistral-7B-Instruct\":\"https://clarifai.com/mistralai/completion/models/mistral-7B-Instruct\",\n",
    "                  \"mistral-large\":\"https://clarifai.com/mistralai/completion/models/mistral-large\",\n",
    "                  \"mistral-small\":\"https://clarifai.com/mistralai/completion/models/mistral-small\",\n",
    "                  \"mistral-medium\":\"https://clarifai.com/mistralai/completion/models/mistral-medium\",\n",
    "                  \"mixtral-8x22B\" : \"https://clarifai.com/mistralai/completion/models/mixtral-8x22B\",\n",
    "                  \"Upstage:solar-10 7b-instruct\":\"https://clarifai.com/upstage/solar/models/solar-10_7b-instruct\",\n",
    "                  \"gcp:gemini-pro\":\"https://clarifai.com/gcp/generate/models/gemini-pro\",\n",
    "                  \"databricks:dbrx-intruct\":\"https://clarifai.com/databricks/drbx/models/dbrx-instruct\",\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values(['clarifai/openai.chat-completion.gpt-4-turbo', 'clarifai/openai.chat-completion.GPT-4', 'clarifai/anthropic.completion.claude-3-opus', 'clarifai/anthropic.completion.claude-v2', 'clarifai/anthropic.completion.claude-2_1', 'clarifai/anthropic.completion.claude-v1', 'clarifai/anthropic.completion.claude-instant-1_2', 'clarifai/meta.Llama-3.Llama-3-8B-Instruct', 'clarifai/meta.Llama-2.llama2-70b-chat', 'clarifai/mistralai.completion.mistral-7B-Instruct', 'clarifai/mistralai.completion.mistral-large', 'clarifai/mistralai.completion.mistral-small', 'clarifai/mistralai.completion.mistral-medium', 'clarifai/mistralai.completion.mixtral-8x22B', 'clarifai/upstage.solar.solar-10_7b-instruct', 'clarifai/gcp.generate.gemini-pro', 'clarifai/databricks.drbx.dbrx-instruct'])\n"
     ]
    }
   ],
   "source": [
    "formatted_output = {}\n",
    "\n",
    "for key, url in model_params.items():\n",
    "    parts = url.split(\"/\")\n",
    "    domain = parts[2].replace(\"www.\", \"\").split(\".\")[0]\n",
    "    path_parts = parts[3]\n",
    "    #print(path_parts)\n",
    "    app_name = parts[4]\n",
    "    model_name = parts[-1]\n",
    "    formatted_output[key] = f\"{domain}/{path_parts}.{app_name}.{model_name}\"\n",
    "\n",
    "print(formatted_output.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['clarifai/meta.Llama-3.Llama-3-8B-Instruct', 'clarifai/gcp.generate.gemma-1_1-7b-it', 'clarifai/mistralai.completion.mixtral-8x22B', 'clarifai/cohere.generate.command-r-plus', 'clarifai/databricks.drbx.dbrx-instruct', 'clarifai/mistralai.completion.mistral-large', 'clarifai/mistralai.completion.mistral-medium', 'clarifai/mistralai.completion.mistral-small', 'clarifai/mistralai.completion.mixtral-8x7B-Instruct-v0_1', 'clarifai/nousresearch.instruction-generation.genstruct-7b', 'clarifai/gcp.generate.gemma-2b-it', 'clarifai/gcp.generate.gemma-7b-it', 'clarifai/deci.decilm.deciLM-7B-instruct', 'clarifai/mistralai.completion.mistral-7B-Instruct', 'clarifai/gcp.generate.gemini-pro', 'clarifai/anthropic.completion.claude-v1', 'clarifai/anthropic.completion.claude-instant-1_2', 'clarifai/anthropic.completion.claude-instant', 'clarifai/anthropic.completion.claude-v2', 'clarifai/anthropic.completion.claude-2_1', 'clarifai/meta.Llama-2.codeLlama-70b-Python', 'clarifai/meta.Llama-2.codeLlama-70b-Instruct', 'clarifai/openai.completion.gpt-3_5-turbo-instruct', 'clarifai/meta.Llama-2.llama2-7b-chat', 'clarifai/meta.Llama-2.llama2-13b-chat', 'clarifai/meta.Llama-2.llama2-70b-chat', 'clarifai/openai.chat-completion.gpt-4-turbo', 'clarifai/microsoft.text-generation.phi-2', 'clarifai/meta.Llama-2.llama2-7b-chat-vllm', 'clarifai/upstage.solar.solar-10_7b-instruct', 'clarifai/openchat.openchat.openchat-3_5-1210', 'clarifai/togethercomputer.stripedHyena.stripedHyena-Nous-7B', 'clarifai/gcp.generate.text-bison', 'clarifai/meta.Llama-2.llamaGuard-7b', 'clarifai/fblgit.una-cybertron.una-cybertron-7b-v2', 'clarifai/clarifai.LLM-OpenSource-Models-Training-Inference-Test.zephyr-7B-beta-GPTQ', 'clarifai/openai.chat-completion.GPT-4', 'clarifai/openai.chat-completion.GPT-3_5-turbo', 'clarifai/ai21.complete.Jurassic2-Grande', 'clarifai/ai21.complete.Jurassic2-Grande-Instruct', 'clarifai/ai21.complete.Jurassic2-Jumbo-Instruct', 'clarifai/ai21.complete.Jurassic2-Jumbo', 'clarifai/ai21.complete.Jurassic2-Large', 'clarifai/cohere.generate.cohere-generate-command', 'clarifai/wizardlm.generate.wizardCoder-Python-34B', 'clarifai/wizardlm.generate.wizardLM-70B', 'clarifai/tiiuae.falcon.falcon-40b-instruct', 'clarifai/togethercomputer.RedPajama.RedPajama-INCITE-7B-Chat', 'clarifai/gcp.generate.code-gecko', 'clarifai/gcp.generate.code-bison', 'clarifai/mistralai.completion.mistral-7B-OpenOrca', 'clarifai/mistralai.completion.openHermes-2-mistral-7B', 'clarifai/clarifai.LLM-OpenSource-Models-Training-Inference-Test.tiiuae-falcon-7b-instruct', 'clarifai/wizardlm.generate.wizardLM-13B', 'clarifai/huggingface-research.zephyr.zephyr-7B-alpha', 'clarifai/wizardlm.generate.wizardCoder-15B', 'clarifai/microsoft.text-generation.phi-1_5', 'clarifai/databricks.Dolly-v2.dolly-v2-12b', 'clarifai/bigcode.code.StarCoder', 'clarifai/salesforce.xgen.xgen-7b-8k-instruct', 'clarifai/mosaicml.mpt.mpt-7b-instruct', 'clarifai/phatvo.bloom.bigscience-bloom-560m']\n"
     ]
    }
   ],
   "source": [
    "from clarifai.client.app import App\n",
    "\n",
    "all_llm_community_models = App(pat=\"c75cc032415e45368be331fdd2c06db0\").list_models(filter_by={\"query\": \"LLM\",\n",
    "                                                        \"model_type_id\": \"text-to-text\"}, only_in_app=False)\n",
    "model_list=[]\n",
    "for model in all_llm_community_models:\n",
    "    #print(model.id)\n",
    "    user_id = model.user_id\n",
    "    app_id = model.app_id\n",
    "    model_id = model.id\n",
    "    model_list.append(f\"clarifai/{user_id}.{app_id}.{model_id}\")\n",
    "\n",
    "print(model_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
